import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score
import joblib
import warnings
warnings.filterwarnings('ignore')

print("ğŸš€ AI ì„œë¹„ìŠ¤ìš© ì²´ì˜¨ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ (ë‚˜ì´ í”¼ì²˜ í¬í•¨)")
print("=" * 60)

# 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
try:
    df = pd.read_csv("/Users/Iris/ì¸ê³µì§€ëŠ¥ì„œë¹„ìŠ¤ê°œë°œ2/data/extracted_data_sampled_20rows.csv")
    print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰, {df.shape[1]}ì—´")
except FileNotFoundError:
    print("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    exit(1)

# sid ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ í›„ ì œê±°
if "sid" in df.columns:
    df = df.drop(columns=["sid"])
    print("âœ… sid ì»¬ëŸ¼ ì œê±° ì™„ë£Œ")

# ê²°ì¸¡ê°’ ì²˜ë¦¬
print(f"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì „: {df.shape[0]}í–‰")
df = df.dropna()
print(f"ê²°ì¸¡ê°’ ì²˜ë¦¬ í›„: {df.shape[0]}í–‰")

# ì˜¨ë„ 0 ê°’ ì œê±° (ë¹„ì •ìƒì ì¸ ë°ì´í„°)
if "TEMP_median" in df.columns:
    temp_zero_count = (df["TEMP_median"] == 0).sum()
    if temp_zero_count > 0:
        print(f"âš ï¸  ì˜¨ë„ 0ì¸ ë¹„ì •ìƒ ë°ì´í„° {temp_zero_count}ê°œ ë°œê²¬, ì œê±°í•©ë‹ˆë‹¤.")
        df = df[df["TEMP_median"] != 0]
        print(f"ì˜¨ë„ 0 ê°’ ì œê±° í›„: {df.shape[0]}í–‰")
    
    # ì˜¨ë„ ë²”ìœ„ í™•ì¸
    temp_min = df["TEMP_median"].min()
    temp_max = df["TEMP_median"].max()
    print(f"ì˜¨ë„ ë²”ìœ„: {temp_min:.2f}Â°C ~ {temp_max:.2f}Â°C")

# ë‚˜ì´ í†µê³„ í™•ì¸
if "age" in df.columns:
    age_min = df["age"].min()
    age_max = df["age"].max()
    age_mean = df["age"].mean()
    print(f"ë‚˜ì´ ë²”ìœ„: {age_min}ì„¸ ~ {age_max}ì„¸ (í‰ê· : {age_mean:.1f}ì„¸)")

# 2ï¸âƒ£ í•„ìˆ˜ í”¼ì²˜ 6ê°œ ì„ íƒ (ë‚˜ì´ í¬í•¨)
print("\nğŸ¯ í•„ìˆ˜ í”¼ì²˜ 6ê°œ ì„ íƒ (ë‚˜ì´ í¬í•¨)")
print("1. bmi (23.2%) - ì²´ì§ˆëŸ‰ì§€ìˆ˜")
print("2. mean_sa02 (16.2%) - ì‚°ì†Œí¬í™”ë„ í‰ê· ") 
print("3. hrv_hr_ratio (14.8%) - HRV/HR ë¹„ìœ¨")
print("4. HRV_SDNN (11.3%) - ì‹¬ë°•ë³€ì´ë„")
print("5. bmi_hr_interaction (10.5%) - BMI Ã— HR ìƒí˜¸ì‘ìš©")
print("6. age (8.7%) - ë‚˜ì´")

# í•„ìˆ˜ í”¼ì²˜ ì •ì˜
essential_features = ['bmi', 'mean_sa02', 'HRV_SDNN', 'HR_mean', 'age']  # age ì¶”ê°€
cat_features = ['gender']

# íŒŒìƒ í”¼ì²˜ ê³„ì‚°
print("\nğŸ”§ í•„ìˆ˜ íŒŒìƒ í”¼ì²˜ ê³„ì‚°")
df['hrv_hr_ratio'] = df['HRV_SDNN'] / df['HR_mean']
df['bmi_hr_interaction'] = df['bmi'] * df['HR_mean']

# ë‚˜ì´ ê´€ë ¨ íŒŒìƒ í”¼ì²˜ ì¶”ê°€
df['age_bmi_interaction'] = df['age'] * df['bmi']  # ë‚˜ì´ì™€ BMI ìƒí˜¸ì‘ìš©
df['age_hrv_ratio'] = df['age'] / (df['HRV_SDNN'] + 1)  # ë‚˜ì´ì™€ HRV ë¹„ìœ¨ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)

# ìµœì¢… í•„ìˆ˜ í”¼ì²˜ (6ê°œ + íŒŒìƒ í”¼ì²˜)
final_features = ['bmi', 'mean_sa02', 'HRV_SDNN', 'hrv_hr_ratio', 'bmi_hr_interaction', 'age', 'age_bmi_interaction', 'age_hrv_ratio']

print(f"âœ… ìµœì¢… í•„ìˆ˜ í”¼ì²˜: {final_features}")

# ì¡´ì¬í•˜ëŠ” íŠ¹ì„±ë§Œ ì„ íƒ
final_features = [f for f in final_features if f in df.columns]
cat_features = [f for f in cat_features if f in df.columns]

print(f"âœ… ì‚¬ìš©í•  ìˆ˜ì¹˜í˜• íŠ¹ì„±: {final_features}")
print(f"âœ… ì‚¬ìš©í•  ë²”ì£¼í˜• íŠ¹ì„±: {cat_features}")

# 3ï¸âƒ£ Train/Valid ë¶„ë¦¬
print("\nğŸ“Š Train/Valid ë¶„ë¦¬")
train_indices, valid_indices = train_test_split(df.index, test_size=0.3, random_state=42)

X_train = df.loc[train_indices, final_features + cat_features]
X_valid = df.loc[valid_indices, final_features + cat_features]
y_train = df.loc[train_indices, "TEMP_median"]
y_valid = df.loc[valid_indices, "TEMP_median"]

print(f"âœ… Train/Valid ë¶„ë¦¬ ì™„ë£Œ:")
print(f"  - í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
print(f"  - ê²€ì¦ ë°ì´í„°: {len(X_valid)}ê°œ")

# 4ï¸âƒ£ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
print("\nğŸ”§ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±")

# ìˆ˜ì¹˜í˜•ê³¼ ë²”ì£¼í˜• íŠ¹ì„±ì— ëŒ€í•œ ì „ì²˜ë¦¬
transformers = []

if final_features:
    transformers.append(("num", StandardScaler(), final_features))

if cat_features:
    transformers.append(("cat", OneHotEncoder(drop='first', handle_unknown='ignore'), cat_features))

if not transformers:
    print("âŒ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤!")
    exit(1)

preprocessor = ColumnTransformer(transformers=transformers)

# 5ï¸âƒ£ ìµœì í™”ëœ ì•™ìƒë¸” ëª¨ë¸
print("\nğŸ¯ ìµœì í™”ëœ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± (ë‚˜ì´ í”¼ì²˜ í¬í•¨)")

# RandomForest íŒŒì´í”„ë¼ì¸
rf_pipeline = Pipeline([
    ("preprocess", preprocessor),
    ("model", RandomForestRegressor(n_estimators=1000, max_depth=20, min_samples_split=3, 
                                   min_samples_leaf=1, random_state=42, n_jobs=-1))
])

# ExtraTrees íŒŒì´í”„ë¼ì¸
et_pipeline = Pipeline([
    ("preprocess", preprocessor),
    ("model", ExtraTreesRegressor(n_estimators=1000, max_depth=25, min_samples_split=2,
                                 min_samples_leaf=1, random_state=42, n_jobs=-1))
])

# GradientBoosting íŒŒì´í”„ë¼ì¸ (ìµœì  íŒŒë¼ë¯¸í„°)
gb_pipeline = Pipeline([
    ("preprocess", preprocessor),
    ("model", GradientBoostingRegressor(
        n_estimators=1000, 
        learning_rate=0.01, 
        max_depth=6, 
        subsample=0.9, 
        random_state=42
    ))
])

# ìµœì í™”ëœ ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
ensemble = VotingRegressor([
    ('rf', rf_pipeline),
    ('et', et_pipeline), 
    ('gb', gb_pipeline)
])

# 6ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
print("\nğŸ“Š ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€")

# ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
ensemble.fit(X_train, y_train)
y_pred_ensemble = ensemble.predict(X_valid)

# ì„±ëŠ¥ í‰ê°€
r2_ensemble = r2_score(y_valid, y_pred_ensemble)
mse_ensemble = mean_squared_error(y_valid, y_pred_ensemble)

print(f"ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ (ë‚˜ì´ í¬í•¨):")
print(f"  RÂ² Score: {r2_ensemble:.4f}")
print(f"  MSE: {mse_ensemble:.4f}")
print(f"  RMSE: {np.sqrt(mse_ensemble):.4f}Â°C")

# êµì°¨ ê²€ì¦ ì„±ëŠ¥
print("\nğŸ“Š êµì°¨ ê²€ì¦ ì„±ëŠ¥ (5-fold CV):")
cv_scores = cross_val_score(ensemble, X_train, y_train, cv=5, scoring='r2')
print(f"  CV RÂ² Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
print(f"  CV ê°œë³„ ì ìˆ˜: {cv_scores}")

# ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€ (ëƒ‰ê¸°/ì ì •/ë”ìœ„)
print("\nğŸ“Š ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€")

# ì˜¨ë„ ë¶„ë¥˜ í•¨ìˆ˜
def classify_temperature(temp, cold_threshold=33.0, hot_threshold=35.0):
    if temp < cold_threshold:
        return "ëƒ‰ê¸°"
    elif temp > hot_threshold:
        return "ë”ìœ„"
    else:
        return "ì ì •"

# ì‹¤ì œ ì˜¨ë„ ë¶„ë¥˜
y_valid_class = [classify_temperature(temp) for temp in y_valid]
y_pred_class = [classify_temperature(temp) for temp in y_pred_ensemble]

print(f"ì˜¨ë„ ë¶„ë¥˜ ì„ê³„ê°’:")
print(f"  ëƒ‰ê¸°: < 33.0Â°C")
print(f"  ì ì •: 33.0Â°C ~ 35.0Â°C")
print(f"  ë”ìœ„: > 35.0Â°C")

print("\në¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
print(classification_report(y_valid_class, y_pred_class, 
                          target_names=["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"]))

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(y_valid_class, y_pred_class, labels=["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"])
print("í˜¼ë™ í–‰ë ¬:")
print("        ì˜ˆì¸¡")
print("ì‹¤ì œ   ëƒ‰ê¸°  ì ì •  ë”ìœ„")
for i, label in enumerate(["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"]):
    print(f"{label:4} {cm[i]}")

# ì „ì²´ ë¶„ë¥˜ ì •í™•ë„
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_valid_class, y_pred_class)
print(f"\nì „ì²´ ë¶„ë¥˜ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")

# ì˜¨ë„ ë²”ìœ„ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ
print("\nì˜¨ë„ ë²”ìœ„ë³„ ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ:")
print("=" * 80)

from sklearn.metrics import precision_recall_fscore_support
import pandas as pd

# ê° í´ë˜ìŠ¤ë³„ ì •ë°€ë„, ì¬í˜„ë¥ , F1 ìŠ¤ì½”ì–´ ê³„ì‚°
precision, recall, f1, support = precision_recall_fscore_support(
    y_valid_class, y_pred_class, labels=["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"], zero_division=0
)

# í´ë˜ìŠ¤ë³„ ìƒì„¸ ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
results_data = []
for i, cat in enumerate(["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"]):
    mask_actual = np.array(y_valid_class) == cat
    mask_pred = np.array(y_pred_class) == cat
    
    actual_count = mask_actual.sum()
    pred_count = mask_pred.sum()
    correct_count = (np.array(y_pred_class)[mask_actual] == cat).sum()
    
    # ì •í™•ë„ (Accuracy) - í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì‹¤ì œ ìƒ˜í”Œ ì¤‘ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ë¹„ìœ¨
    class_accuracy = correct_count / actual_count if actual_count > 0 else 0
    
    # ì •ë°€ë„ (Precision) - í•´ë‹¹ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œë¡œ ë§ëŠ” ë¹„ìœ¨
    precision_val = precision[i]
    
    # ì¬í˜„ë¥  (Recall) - ì‹¤ì œ í•´ë‹¹ í´ë˜ìŠ¤ì¸ ê²ƒ ì¤‘ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ë¹„ìœ¨
    recall_val = recall[i]
    
    # F1 ìŠ¤ì½”ì–´ - ì •ë°€ë„ì™€ ì¬í˜„ë¥ ì˜ ì¡°í™”í‰ê· 
    f1_val = f1[i]
    
    # ì§€ì›ë„ (Support) - ì‹¤ì œ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜
    support_val = support[i]
    
    results_data.append({
        'í´ë˜ìŠ¤': cat,
        'ì‹¤ì œ ìƒ˜í”Œ ìˆ˜': actual_count,
        'ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜': pred_count,
        'í´ë˜ìŠ¤ë³„ ì •í™•ë„ (%)': f"{class_accuracy*100:.2f}",
        'ì •ë°€ë„ (%)': f"{precision_val*100:.2f}",
        'ì¬í˜„ë¥  (%)': f"{recall_val*100:.2f}",
        'F1 ìŠ¤ì½”ì–´ (%)': f"{f1_val*100:.2f}",
        'ì§€ì›ë„': support_val
    })

# DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œ í˜•íƒœë¡œ ì¶œë ¥
df_results = pd.DataFrame(results_data)
print("\nğŸ“Š í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì§€í‘œ í‘œ:")
print(df_results.to_string(index=False))

# ì „ì²´ í‰ê·  ì„±ëŠ¥ ì§€í‘œ
print(f"\nğŸ“ˆ ì „ì²´ í‰ê·  ì„±ëŠ¥ ì§€í‘œ:")
print(f"  í‰ê·  ì •ë°€ë„ (Macro): {precision.mean():.4f} ({precision.mean()*100:.2f}%)")
print(f"  í‰ê·  ì¬í˜„ë¥  (Macro): {recall.mean():.4f} ({recall.mean()*100:.2f}%)")
print(f"  í‰ê·  F1 ìŠ¤ì½”ì–´ (Macro): {f1.mean():.4f} ({f1.mean()*100:.2f}%)")

# ê°€ì¤‘ í‰ê·  ì„±ëŠ¥ ì§€í‘œ (í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ì— ë¹„ë¡€)
from sklearn.metrics import precision_recall_fscore_support
precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
    y_valid_class, y_pred_class, labels=["ëƒ‰ê¸°", "ì ì •", "ë”ìœ„"], average='weighted', zero_division=0
)

print(f"\nğŸ“ˆ ê°€ì¤‘ í‰ê·  ì„±ëŠ¥ ì§€í‘œ:")
print(f"  ê°€ì¤‘ í‰ê·  ì •ë°€ë„: {precision_weighted:.4f} ({precision_weighted*100:.2f}%)")
print(f"  ê°€ì¤‘ í‰ê·  ì¬í˜„ë¥ : {recall_weighted:.4f} ({recall_weighted*100:.2f}%)")
print(f"  ê°€ì¤‘ í‰ê·  F1 ìŠ¤ì½”ì–´: {f1_weighted:.4f} ({f1_weighted*100:.2f}%)")

# ìš”ì•½ í‘œ ìƒì„±
summary_data = [
    ['Macro í‰ê· ', f"{precision.mean()*100:.2f}%", f"{recall.mean()*100:.2f}%", f"{f1.mean()*100:.2f}%"],
    ['Weighted í‰ê· ', f"{precision_weighted*100:.2f}%", f"{recall_weighted*100:.2f}%", f"{f1_weighted*100:.2f}%"]
]

df_summary = pd.DataFrame(summary_data, columns=['í‰ê·  ìœ í˜•', 'ì •ë°€ë„', 'ì¬í˜„ë¥ ', 'F1 ìŠ¤ì½”ì–´'])
print(f"\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥ ìš”ì•½ í‘œ:")
print(df_summary.to_string(index=False))

# 7ï¸âƒ£ ëª¨ë¸ ì €ì¥
print("\nğŸ’¾ ëª¨ë¸ ì €ì¥")
model_path = '/Users/Iris/ì¸ê³µì§€ëŠ¥ì„œë¹„ìŠ¤ê°œë°œ2/model/ai_thermal_model_with_age.pkl'
joblib.dump(ensemble, model_path)
print(f"âœ… AI ì„œë¹„ìŠ¤ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

# 8ï¸âƒ£ ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ë° ì €ì¥
def predict_temperature_with_age(hr_mean, hrv_sdnn, bmi, mean_sa02, gender, age):
    """
    ì²´ì˜¨ ì˜ˆì¸¡ í•¨ìˆ˜ (ë‚˜ì´ í¬í•¨)
    
    Parameters:
    - hr_mean: í‰ê·  ì‹¬ë°•ìˆ˜
    - hrv_sdnn: ì‹¬ë°•ë³€ì´ë„ (SDNN)
    - bmi: ì²´ì§ˆëŸ‰ì§€ìˆ˜
    - mean_sa02: í‰ê·  ì‚°ì†Œí¬í™”ë„
    - gender: ì„±ë³„ ('M' ë˜ëŠ” 'F')
    - age: ë‚˜ì´
    
    Returns:
    - ì˜ˆì¸¡ëœ ì²´ì˜¨ (Â°C)
    """
    # íŒŒìƒ í”¼ì²˜ ê³„ì‚°
    hrv_hr_ratio = hrv_sdnn / hr_mean
    bmi_hr_interaction = bmi * hr_mean
    age_bmi_interaction = age * bmi
    age_hrv_ratio = age / (hrv_sdnn + 1)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    
    # ë°ì´í„° ì¤€ë¹„
    data = pd.DataFrame({
        'bmi': [bmi],
        'mean_sa02': [mean_sa02], 
        'HRV_SDNN': [hrv_sdnn],
        'hrv_hr_ratio': [hrv_hr_ratio],
        'bmi_hr_interaction': [bmi_hr_interaction],
        'age': [age],
        'age_bmi_interaction': [age_bmi_interaction],
        'age_hrv_ratio': [age_hrv_ratio],
        'gender': [gender]
    })
    
    # ì˜ˆì¸¡
    temp_pred = ensemble.predict(data)[0]
    return temp_pred

# ì˜ˆì¸¡ í•¨ìˆ˜ë„ í•¨ê»˜ ì €ì¥
import pickle
with open('/Users/Iris/ì¸ê³µì§€ëŠ¥ì„œë¹„ìŠ¤ê°œë°œ2/model/predict_function_with_age.pkl', 'wb') as f:
    pickle.dump(predict_temperature_with_age, f)

print("âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ì €ì¥ ì™„ë£Œ: predict_function_with_age.pkl")

# 9ï¸âƒ£ ë‚˜ì´ë³„ ì„±ëŠ¥ ë¶„ì„
print("\nğŸ“Š ë‚˜ì´ë³„ ì„±ëŠ¥ ë¶„ì„")
df_valid_with_age = df.loc[valid_indices].copy()
df_valid_with_age['pred_temp'] = y_pred_ensemble
df_valid_with_age['temp_error'] = abs(df_valid_with_age['TEMP_median'] - df_valid_with_age['pred_temp'])

# ë‚˜ì´ ê·¸ë£¹ë³„ ì„±ëŠ¥
df_valid_with_age['age_group'] = pd.cut(df_valid_with_age['age'], 
                                       bins=[0, 30, 50, 70, 100], 
                                       labels=['ì²­ë…„(30ì„¸ë¯¸ë§Œ)', 'ì¤‘ë…„(30-50ì„¸)', 'ì¥ë…„(50-70ì„¸)', 'ë…¸ë…„(70ì„¸ì´ìƒ)'])

age_performance = df_valid_with_age.groupby('age_group').agg({
    'temp_error': ['mean', 'std', 'count'],
    'TEMP_median': ['mean', 'std'],
    'pred_temp': ['mean', 'std']
}).round(3)

print("ë‚˜ì´ ê·¸ë£¹ë³„ ì˜ˆì¸¡ ì„±ëŠ¥:")
print(age_performance)

# ğŸ”Ÿ ìµœì¢… ìš”ì•½
print("\n" + "=" * 60)
print("AI ì„œë¹„ìŠ¤ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ë‚˜ì´ í”¼ì²˜ í¬í•¨)")
print("=" * 60)

print("ğŸ“Š ëª¨ë¸ ì •ë³´:")
print(f"- í”¼ì²˜ ìˆ˜: {len(final_features)}ê°œ (ë‚˜ì´ í¬í•¨)")
print(f"- RÂ² Score: {r2_ensemble:.4f}")
print(f"- RMSE: {np.sqrt(mse_ensemble):.4f}Â°C")

print("\nğŸ”¥ ì£¼ìš” íŠ¹ì§•:")
print("âœ… í•„ìˆ˜ í”¼ì²˜ 6ê°œ + íŒŒìƒ í”¼ì²˜ ì‚¬ìš© (ë‚˜ì´ í¬í•¨)")
print("âœ… ì•™ìƒë¸” ëª¨ë¸ (RandomForest + ExtraTrees + GradientBoosting)")
print("âœ… ë‚˜ì´ë³„ ë§ì¶¤í˜• ì˜ˆì¸¡")
print("âœ… ì‹¤ì‹œê°„ ì˜ˆì¸¡ ìµœì í™”")
print("âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì ")

print("\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
print("- ai_thermal_model_with_age.pkl: í•™ìŠµëœ ëª¨ë¸ (ë‚˜ì´ í¬í•¨)")
print("- predict_function_with_age.pkl: ì˜ˆì¸¡ í•¨ìˆ˜ (ë‚˜ì´ í¬í•¨)")

print(f"\nğŸ† AI ì„œë¹„ìŠ¤ìš© ì²´ì˜¨ ì˜ˆì¸¡ ëª¨ë¸ ì™„ì„±! (ë‚˜ì´ í”¼ì²˜ í¬í•¨) ğŸ‰")
