# Multiple Classifiers Comparison Report
## 8ê°€ì§€ ë¶„ë¥˜ê¸° ì„±ëŠ¥ ë¹„êµ ë¶„ì„

**ì‘ì„±ì¼**: 2025-10-14  
**ëª¨ë¸**: 8ê°€ì§€ ë¶„ë¥˜ê¸° (Random Forest, XGBoost, SVM, Logistic Regression, KNN, Naive Bayes, Decision Tree, CatBoost)  
**ë°ì´í„°**: 4,606ê°œ ìƒ˜í”Œ (S046 ì´ìƒì¹˜ ì œê±° í›„)  
**ìµœì¢… ì„±ëŠ¥**: CatBoost F1-score 0.6866 (1ìœ„)

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë°ì´í„° ì „ì²˜ë¦¬](#ë°ì´í„°-ì „ì²˜ë¦¬)
3. [ëª¨ë¸ ì„¤ì •](#ëª¨ë¸-ì„¤ì •)
4. [ì„±ëŠ¥ ê²°ê³¼](#ì„±ëŠ¥-ê²°ê³¼)
5. [í´ë˜ìŠ¤ë³„ ë¶„ì„](#í´ë˜ìŠ¤ë³„-ë¶„ì„)
6. [íŠ¹ì„± ì¤‘ìš”ë„](#íŠ¹ì„±-ì¤‘ìš”ë„)
7. [ëª¨ë¸ ì €ì¥](#ëª¨ë¸-ì €ì¥)
8. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
9. [ê²°ë¡ ](#ê²°ë¡ )

---

## ê°œìš”

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” **ì²´ì˜¨ ì˜ˆì¸¡ì„ ìœ„í•œ 8ê°€ì§€ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„**í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ëª©í‘œ

- **ì²´ì˜¨ ë¶„ë¥˜**: ì¶”ì›€(33Â°C ë¯¸ë§Œ), ì¾Œì (33-35Â°C), ë”ì›€(35Â°C ì´ˆê³¼)
- **ì•Œê³ ë¦¬ì¦˜ ë¹„êµ**: 8ê°€ì§€ ë¶„ë¥˜ê¸° ì„±ëŠ¥ í‰ê°€
- **ìµœì  ëª¨ë¸ ì„ ì •**: F1-score ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë„ì¶œ
- **íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„**: ì²´ì˜¨ ì˜ˆì¸¡ì— ì¤‘ìš”í•œ ìƒì²´ ì‹ í˜¸ íŒŒì•…

### ğŸ“Š ë¶„ì„ ë²”ìœ„

- **ë°ì´í„°**: 4,606ê°œ ìƒ˜í”Œ (ì›ë³¸ 4,649ê°œì—ì„œ S046 ì´ìƒì¹˜ 43ê°œ ì œê±°)
- **íŠ¹ì„±**: 6ê°œ (BMI, mean_sa02, HRV_SDNN, HR_mean, Gender_F, Gender_M)
- **í‰ê°€**: 5-Fold Cross-Validation + F1-score ê¸°ì¤€
- **ëª¨ë¸**: 8ê°€ì§€ ë¶„ë¥˜ê¸° ë™ì‹œ ë¹„êµ

---

## ë°ì´í„° ì „ì²˜ë¦¬

### ğŸ§¹ ë°ì´í„° ì •ì œ

```python
# S046ì˜ temp_medianì´ 0ì¸ ë°ì´í„° ì œê±°
df_clean = df[~((df['sid'] == 'S046') & (df['TEMP_median'] == 0))]
```

**ê²°ê³¼**:
- ì›ë³¸ ë°ì´í„°: 4,649ê°œ ìƒ˜í”Œ
- ì •ì œ í›„: 4,606ê°œ ìƒ˜í”Œ
- ì œê±°ëœ ì´ìƒì¹˜: 43ê°œ (0.9%)

### ğŸ·ï¸ ë¼ë²¨ ë¶„í¬

| í´ë˜ìŠ¤ | ë¼ë²¨ | ì˜¨ë„ ë²”ìœ„ | ìƒ˜í”Œ ìˆ˜ | ë¹„ìœ¨ |
|--------|------|-----------|---------|------|
| ì¶”ì›€ | 0 | 33Â°C ë¯¸ë§Œ | 1,104ê°œ | 24.0% |
| ì¾Œì  | 1 | 33-35Â°C | 2,472ê°œ | 53.7% |
| ë”ì›€ | 2 | 35Â°C ì´ˆê³¼ | 1,030ê°œ | 22.4% |

### ğŸ“Š íŠ¹ì„± ì„ íƒ

```python
# 6ê°œ íŠ¹ì„± ì‚¬ìš©
basic_features = ['bmi', 'mean_sa02', 'HRV_SDNN', 'HR_mean']
gender_dummies = pd.get_dummies(df['gender'], prefix='Gender')
feature_columns = basic_features + list(gender_dummies.columns)
```

**íŠ¹ì„± ëª©ë¡**:
1. `bmi` - ì²´ì§ˆëŸ‰ì§€ìˆ˜
2. `mean_sa02` - í‰ê·  ì‚°ì†Œí¬í™”ë„
3. `HRV_SDNN` - ì‹¬ë°•ë³€ì´ë„
4. `HR_mean` - í‰ê·  ì‹¬ë°•ìˆ˜
5. `Gender_F` - ì„±ë³„ (ì—¬ì„±)
6. `Gender_M` - ì„±ë³„ (ë‚¨ì„±)

---

## ëª¨ë¸ ì„¤ì •

### ğŸ—ï¸ 8ê°€ì§€ ë¶„ë¥˜ê¸° í•˜ì´í¼íŒŒë¼ë¯¸í„°

#### 1. Random Forest
```python
RandomForestClassifier(
    n_estimators=100, 
    random_state=42, 
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2
)
```

#### 2. XGBoost
```python
xgb.XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    eval_metric='mlogloss'
)
```

#### 3. SVM
```python
SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale',
    random_state=42,
    probability=True
)
```

#### 4. Logistic Regression
```python
LogisticRegression(
    random_state=42,
    max_iter=1000,
    multi_class='ovr'
)
```

#### 5. K-Nearest Neighbors
```python
KNeighborsClassifier(
    n_neighbors=5,
    weights='distance'
)
```

#### 6. Naive Bayes
```python
GaussianNB()
```

#### 7. Decision Tree
```python
DecisionTreeClassifier(
    random_state=42,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2
)
```

#### 8. CatBoost
```python
CatBoostClassifier(
    iterations=500,
    learning_rate=0.1,
    depth=6,
    l2_leaf_reg=3,
    random_seed=42,
    verbose=False
)
```

### âš™ï¸ ê³µí†µ ì„¤ì •

- **ë°ì´í„° ë¶„í• **: 80% í•™ìŠµ, 20% ê²€ì¦
- **Stratified Split**: í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
- **ìŠ¤ì¼€ì¼ë§**: SVM, Logistic Regression, KNNì—ë§Œ ì ìš©
- **Cross-Validation**: 5-Fold (F1-score ê¸°ì¤€)

---

## ì„±ëŠ¥ ê²°ê³¼

### ğŸ† 8ê°€ì§€ ë¶„ë¥˜ê¸° ì„±ëŠ¥ ìˆœìœ„

| ìˆœìœ„ | ëª¨ë¸ | F1-score (macro) | ì •í™•ë„ | CV í‰ê·  | CV í‘œì¤€í¸ì°¨ |
|------|------|------------------|--------|---------|-------------|
| 1 | **CatBoost** | **0.6866** | **0.7180** | **0.6861** | **Â±0.0106** |
| 2 | **XGBoost** | **0.6600** | **0.6985** | **0.6704** | **Â±0.0342** |
| 3 | **Random Forest** | **0.6536** | **0.7007** | **0.6535** | **Â±0.0225** |
| 4 | **Decision Tree** | **0.6484** | **0.6757** | **0.6447** | **Â±0.0284** |
| 5 | **K-Nearest Neighbors** | **0.6353** | **0.6605** | **0.6206** | **Â±0.0087** |
| 6 | **Naive Bayes** | **0.4362** | **0.4751** | **0.4387** | **Â±0.0271** |
| 7 | **SVM** | **0.3401** | **0.5521** | **0.3784** | **Â±0.0420** |
| 8 | **Logistic Regression** | **0.2523** | **0.5423** | **0.2606** | **Â±0.0069** |

### ğŸ“Š ìƒì„¸ ì„±ëŠ¥ ë¶„ì„

#### ğŸ¥‡ 1ìœ„: CatBoost
- **F1-score**: 0.6866 (ìµœê³ )
- **ì •í™•ë„**: 0.7180
- **CV ì•ˆì •ì„±**: Â±0.0106 (ë§¤ìš° ì•ˆì •ì )
- **íŠ¹ì§•**: Gradient Boosting, ë²”ì£¼í˜• ë³€ìˆ˜ ìµœì í™”

#### ğŸ¥ˆ 2ìœ„: XGBoost
- **F1-score**: 0.6600
- **ì •í™•ë„**: 0.6985
- **CV ì•ˆì •ì„±**: Â±0.0342 (ì•ˆì •ì )
- **íŠ¹ì§•**: Gradient Boosting, ë¹ ë¥¸ í•™ìŠµ

#### ğŸ¥‰ 3ìœ„: Random Forest
- **F1-score**: 0.6536
- **ì •í™•ë„**: 0.7007
- **CV ì•ˆì •ì„±**: Â±0.0225 (ì•ˆì •ì )
- **íŠ¹ì§•**: ì•™ìƒë¸”, í•´ì„ ê°€ëŠ¥ì„±

---

## í´ë˜ìŠ¤ë³„ ë¶„ì„

### ğŸ“ˆ í´ë˜ìŠ¤ë³„ F1-score (ìƒìœ„ 5ê°œ ëª¨ë¸)

| ëª¨ë¸ | ì¶”ì›€ (0) | ì¾Œì  (1) | ë”ì›€ (2) | ê· í˜•ë„ |
|------|----------|----------|----------|--------|
| **CatBoost** | **0.643** | **0.771** | **0.645** | **0.064** |
| **XGBoost** | **0.610** | **0.762** | **0.608** | **0.077** |
| **Random Forest** | **0.575** | **0.768** | **0.617** | **0.097** |
| **Decision Tree** | **0.607** | **0.730** | **0.608** | **0.062** |
| **K-Nearest Neighbors** | **0.560** | **0.718** | **0.628** | **0.079** |

### ğŸ¯ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„

#### ë¬¸ì œì 
- **ì¾Œì  í´ë˜ìŠ¤**: 53.7% (ê³¼ë‹¤ í‘œí˜„)
- **ì¶”ì›€ í´ë˜ìŠ¤**: 24.0% (ì ì ˆ)
- **ë”ì›€ í´ë˜ìŠ¤**: 22.4% (ì ì ˆ)

#### í•´ê²°ì±…
- **F1-score ì‚¬ìš©**: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™”í‰ê· 
- **Stratified Split**: ê° Foldì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€
- **í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ê°œë³„ í´ë˜ìŠ¤ F1-score ì¶”ì 

### ğŸ“Š ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ìƒì„¸ ë¶„ì„

#### CatBoost (1ìœ„)
```
F1-score (macro): 0.6866
ì •í™•ë„: 0.7180
êµì°¨ ê²€ì¦ F1-score: 0.6861 Â± 0.0106

í´ë˜ìŠ¤ë³„ F1-score:
- ì¶”ì›€: 0.6434
- ì¾Œì : 0.7712  
- ë”ì›€: 0.6452

í´ë˜ìŠ¤ë³„ F1-score í‘œì¤€í¸ì°¨: 0.0599 (ìƒë‹¹íˆ ê· í˜•ì¡í˜)
```

---

## íŠ¹ì„± ì¤‘ìš”ë„

### ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (CatBoost ê¸°ì¤€)

| ìˆœìœ„ | íŠ¹ì„± | ì¤‘ìš”ë„ | ì„¤ëª… |
|------|------|--------|------|
| 1 | **BMI** | ìµœê³  | ì²´ì§ˆëŸ‰ì§€ìˆ˜ - ì²´ì˜¨ ì¡°ì ˆì— ì§ì ‘ì  ì˜í–¥ |
| 2 | **mean_sa02** | ë†’ìŒ | í‰ê·  ì‚°ì†Œí¬í™”ë„ - ì‹ ì§„ëŒ€ì‚¬ ê´€ë ¨ |
| 3 | **HRV_SDNN** | ì¤‘ê°„ | ì‹¬ë°•ë³€ì´ë„ - ììœ¨ì‹ ê²½ê³„ ìƒíƒœ |
| 4 | **HR_mean** | ì¤‘ê°„ | í‰ê·  ì‹¬ë°•ìˆ˜ - ì‹ ì§„ëŒ€ì‚¬ í™œë™ |
| 5 | **Gender_F** | ë‚®ìŒ | ì„±ë³„ (ì—¬ì„±) |
| 6 | **Gender_M** | ë‚®ìŒ | ì„±ë³„ (ë‚¨ì„±) |

### ğŸ’¡ íŠ¹ì„±ë³„ í•´ì„

#### 1. **BMI (Body Mass Index)**
- **ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±**
- ì²´ì§€ë°©ëŸ‰ì´ ì²´ì˜¨ ì¡°ì ˆì— ì§ì ‘ì  ì˜í–¥
- ë†’ì€ BMI â†’ ì²´ì˜¨ ìƒìŠ¹ ê²½í–¥

#### 2. **mean_sa02 (í‰ê·  ì‚°ì†Œí¬í™”ë„)**
- **ë‘ ë²ˆì§¸ë¡œ ì¤‘ìš”í•œ íŠ¹ì„±**
- ì‚°ì†Œ ê³µê¸‰ê³¼ ì‹ ì§„ëŒ€ì‚¬ ê´€ë ¨
- ë‚®ì€ ì‚°ì†Œí¬í™”ë„ â†’ ì²´ì˜¨ ì¡°ì ˆ ì–´ë ¤ì›€

#### 3. **HRV_SDNN (ì‹¬ë°•ë³€ì´ë„)**
- **ììœ¨ì‹ ê²½ê³„ ìƒíƒœ** ì§€í‘œ
- ìŠ¤íŠ¸ë ˆìŠ¤, í”¼ë¡œë„ì™€ ê´€ë ¨
- ë‚®ì€ HRV â†’ ì²´ì˜¨ ì¡°ì ˆ ê¸°ëŠ¥ ì €í•˜

#### 4. **HR_mean (í‰ê·  ì‹¬ë°•ìˆ˜)**
- **ì‹ ì§„ëŒ€ì‚¬ í™œë™** ì§€í‘œ
- ë†’ì€ ì‹¬ë°•ìˆ˜ â†’ ë†’ì€ ì‹ ì§„ëŒ€ì‚¬ â†’ ì²´ì˜¨ ìƒìŠ¹

#### 5. **Gender (ì„±ë³„)**
- **ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì¤‘ìš”ë„**
- ë‚¨ë…€ ê°„ ì²´ì˜¨ ì¡°ì ˆ ì°¨ì´
- ì—¬ì„±ì´ ì²´ì˜¨ ì¡°ì ˆì— ë” ë¯¼ê°

---

## ëª¨ë¸ ì €ì¥

### ğŸ“ ì €ì¥ë˜ëŠ” íŒŒì¼ë“¤

```
saved_models/
â”œâ”€â”€ scaler.pkl                           # ìŠ¤ì¼€ì¼ëŸ¬
â”œâ”€â”€ feature_columns.pkl                  # íŠ¹ì„± ì»¬ëŸ¼
â”œâ”€â”€ random_forest_model.pkl              # Random Forest
â”œâ”€â”€ xgboost_model.pkl                    # XGBoost
â”œâ”€â”€ svm_model.pkl                        # SVM
â”œâ”€â”€ logistic_regression_model.pkl        # Logistic Regression
â”œâ”€â”€ k_nearest_neighbors_model.pkl        # KNN
â”œâ”€â”€ naive_bayes_model.pkl                # Naive Bayes
â”œâ”€â”€ decision_tree_model.pkl              # Decision Tree
â””â”€â”€ catboost_model.cbm                   # CatBoost
```

### ğŸ”§ ì €ì¥ ê¸°ëŠ¥

```python
def save_models(results, scaler, feature_columns):
    """ëª¨ë“  ëª¨ë¸ì„ pkl íŒŒì¼ë¡œ ì €ì¥"""
    # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('saved_models', exist_ok=True)
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë° íŠ¹ì„± ì»¬ëŸ¼ ì €ì¥
    joblib.dump(scaler, 'saved_models/scaler.pkl')
    joblib.dump(feature_columns, 'saved_models/feature_columns.pkl')
    
    # ê° ëª¨ë¸ ì €ì¥ (CatBoostëŠ” .cbm í˜•ì‹)
    for result in results:
        model_name = result['name'].replace(' ', '_').replace('-', '_')
        if model_name == 'CatBoost':
            result['classifier'].save_model(f'saved_models/{model_name.lower()}_model.cbm')
        else:
            joblib.dump(result['classifier'], f'saved_models/{model_name.lower()}_model.pkl')
```

---

## ì‚¬ìš© ë°©ë²•

### ğŸš€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
python multiple_classifiers_comparison.py
```

### ğŸ“Š ìƒì„±ë˜ëŠ” ê²°ê³¼ë¬¼

#### 1. ì½˜ì†” ì¶œë ¥
- ê° ëª¨ë¸ë³„ í•™ìŠµ ì§„í–‰ ìƒí™©
- ì„±ëŠ¥ ì§€í‘œ (F1-score, ì •í™•ë„)
- í´ë˜ìŠ¤ë³„ F1-score
- ìµœì¢… ìˆœìœ„í‘œ

#### 2. ì‹œê°í™” íŒŒì¼
- `multiple_classifiers_comparison_f1.png` - ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„

#### 3. ëª¨ë¸ íŒŒì¼
- `saved_models/` í´ë”ì— ëª¨ë“  ëª¨ë¸ ì €ì¥

### ğŸ”§ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡

```python
from model_loader import ModelLoader

# ëª¨ë¸ ë¡œë” ìƒì„±
loader = ModelLoader()

# ë‹¤ì¤‘ ë¶„ë¥˜ê¸° ëª¨ë¸ë“¤ ë¡œë“œ
loader.load_multiple_classifiers()

# ì˜ˆì¸¡ ìˆ˜í–‰
predictions, probabilities = loader.predict_temperature(data, 'CatBoost')
```

---

## ê²°ë¡ 

### âœ… ì£¼ìš” ì„±ê³¼

#### 1. **ìµœì  ëª¨ë¸ ì„ ì •**
- **CatBoost**ê°€ F1-score 0.6866ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥
- **XGBoost**ê°€ 0.6600ìœ¼ë¡œ 2ìœ„
- **Random Forest**ê°€ 0.6536ìœ¼ë¡œ 3ìœ„

#### 2. **íŠ¹ì„± ì¤‘ìš”ë„ ëª…í™•í™”**
- **BMI**ê°€ ì²´ì˜¨ ì˜ˆì¸¡ì— ê°€ì¥ ì¤‘ìš”
- **mean_sa02**ê°€ ë‘ ë²ˆì§¸ë¡œ ì¤‘ìš”
- **Gender** ì •ë³´ê°€ ì¶”ê°€ ì˜ˆì¸¡ë ¥ ì œê³µ

#### 3. **ëª¨ë¸ ì•ˆì •ì„± í™•ë³´**
- **Cross-Validation**ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€
- **Tree-based ëª¨ë¸ë“¤**ì´ ê°€ì¥ ì•ˆì •ì 
- **CatBoost**ì˜ CV í‘œì¤€í¸ì°¨ Â±0.0106 (ë§¤ìš° ì•ˆì •ì )

### ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

#### 1. **Gradient Boostingì˜ ìš°ìˆ˜ì„±**
- CatBoost, XGBoostê°€ ìƒìœ„ê¶Œ
- **ìˆœì°¨ì  í•™ìŠµ**ìœ¼ë¡œ ë³µì¡í•œ íŒ¨í„´ í¬ì°©
- **ê³¼ì í•© ë°©ì§€** ë©”ì»¤ë‹ˆì¦˜ ë‚´ì¥

#### 2. **íŠ¹ì„± ì¡°í•© íš¨ê³¼**
- **6ê°œ íŠ¹ì„±** ì¡°í•©ì´ íš¨ê³¼ì 
- **BMI + mean_sa02**ê°€ í•µì‹¬ ì¡°í•©
- **Gender ì •ë³´**ê°€ ì¶”ê°€ ì˜ˆì¸¡ë ¥ ì œê³µ

#### 3. **í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘**
- **F1-score** ì‚¬ìš©ìœ¼ë¡œ ë¶ˆê· í˜• ë¬¸ì œ ì™„í™”
- **Stratified Split**ìœ¼ë¡œ ê³µì •í•œ í‰ê°€
- **í´ë˜ìŠ¤ë³„ ì„±ëŠ¥** ëª¨ë‹ˆí„°ë§

### ğŸš€ ê¶Œì¥ì‚¬í•­

#### 1. **í”„ë¡œë•ì…˜ ëª¨ë¸ ì„ íƒ**
```python
# ìµœì¢… ê¶Œì¥ ëª¨ë¸: CatBoost
model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.1,
    depth=6,
    l2_leaf_reg=3,
    random_seed=42,
    verbose=False
)
```

#### 2. **íŠ¹ì„± ìš°ì„ ìˆœìœ„**
1. **BMI** (í•„ìˆ˜)
2. **mean_sa02** (í•„ìˆ˜)
3. **HRV_SDNN** (ê¶Œì¥)
4. **HR_mean** (ê¶Œì¥)
5. **Gender** (ì„ íƒ)

#### 3. **ëª¨ë¸ ê°œì„  ë°©í–¥**
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹** (Optuna, GridSearch)
- **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§** (ìƒí˜¸ì‘ìš© í•­ëª©)
- **ì•™ìƒë¸” ëª¨ë¸** (CatBoost + XGBoost)
- **ë” ë§ì€ ë°ì´í„°** ìˆ˜ì§‘

---

## ë¶€ë¡

### ğŸ“š ì½”ë“œ êµ¬ì¡°

#### ì£¼ìš” í•¨ìˆ˜
- `load_and_preprocess_data()` - ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
- `create_temperature_labels()` - ì˜¨ë„ ë¼ë²¨ ìƒì„±
- `prepare_features()` - íŠ¹ì„± ì¤€ë¹„
- `get_classifiers()` - ë¶„ë¥˜ê¸° ì •ì˜
- `train_and_evaluate_classifiers()` - ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
- `plot_comparison_results()` - ê²°ê³¼ ì‹œê°í™”
- `save_models()` - ëª¨ë¸ ì €ì¥

#### í‰ê°€ ë©”íŠ¸ë¦­
- **F1-score (macro)**: í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³ ë ¤
- **ì •í™•ë„**: ì „ì²´ ë¶„ë¥˜ ì •í™•ë„
- **Cross-Validation**: 5-Foldë¡œ ì•ˆì •ì„± í‰ê°€

### ğŸ”— ê´€ë ¨ íŒŒì¼

- `multiple_classifiers_comparison.py` - ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
- `model_loader.py` - ëª¨ë¸ ë¡œë”© ìœ í‹¸ë¦¬í‹°
- `multiple_classifiers_comparison_f1.png` - ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„
- `saved_models/` - ì €ì¥ëœ ëª¨ë¸ë“¤

---

**ë¬¸ì„œ ì‘ì„±**: 2025-01-27  
**ë¶„ì„ ëŒ€ìƒ**: multiple_classifiers_comparison.py  
**ì‘ì„±ì**: AI Assistant  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-01-27
